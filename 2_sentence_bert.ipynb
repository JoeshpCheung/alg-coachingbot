{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa387713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine similarity score: 0.5259402\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# SentenceTransformers Bert MiniLM,推荐使用\n",
    "class SentenceTransformers():\n",
    "    def __init__(self, dir_path='embed/paraphrase-multilingual-MiniLM-L12-v2/'):\n",
    "        self.dir_path = dir_path\n",
    "        self.model = AutoModel.from_pretrained(dir_path)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(dir_path)\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "    def get_embed(self, sentence1, sentence2):\n",
    "        sentences = [sentence1, sentence2]\n",
    "        # Tokenize sentences\n",
    "        encoded_input = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "        \n",
    "        # Compute token embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = self.model(**encoded_input)\n",
    "            \n",
    "        # Perform pooling. In this case, max pooling.\n",
    "        sentence_embeddings = self.mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "        return sentence_embeddings[0], sentence_embeddings[1]\n",
    "        \n",
    "    def cal_cosine_similarity(self, embed1, embed2):\n",
    "        embed1 = np.array(embed1)\n",
    "        embed2 = np.array(embed2)\n",
    "        if embed1.size>0 and embed2.size>0:\n",
    "            m1 = np.linalg.norm(embed1)\n",
    "            m2 = np.linalg.norm(embed2)\n",
    "\n",
    "            sim = np.matmul(embed1,embed2) / (m1*m2)\n",
    "        else:\n",
    "            sim = 0\n",
    "            \n",
    "        return sim\n",
    "    \n",
    "    def sentence_similarity(self, text1, text2):\n",
    "        embed1, embed2 = self.get_embed(text1, text2)\n",
    "        cos_sim_score = self.cal_cosine_similarity(embed1, embed2)\n",
    "        \n",
    "        return cos_sim_score\n",
    "\n",
    "\n",
    "text1 = '我是个好人'\n",
    "text2 = '我是个坏人'\n",
    "st = SentenceTransformers()\n",
    "res = st.sentence_similarity(text1, text2)\n",
    "print('cosine similarity score:', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05729e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dir_path = '/home/jasoncheung/project/work/alg-coachingbot/datas/'\n",
    "df_normal = pd.read_excel(dir_path+'normal_QC.xlsx')\n",
    "df_bank = pd.read_excel(dir_path+'bank_QC.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b32e3659",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normal_score_w2v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_949153/3592820858.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtmp_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentence_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnormal_score_st\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf_normal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'st_score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormal_score_w2v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbank_score_st\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normal_score_w2v' is not defined"
     ]
    }
   ],
   "source": [
    "# cal w2v cos similarity\n",
    "normal_score_st = []\n",
    "for t1, t2 in zip(df_normal.text1.tolist(), df_normal.text2.tolist()):\n",
    "    tmp_score = st.sentence_similarity(t1, t2)\n",
    "    normal_score_st.append(tmp_score)\n",
    "df_normal['st_score'] = normal_score_st\n",
    "\n",
    "bank_score_st = []\n",
    "for t1, t2 in zip(df_bank.text1.tolist(), df_bank.text2.tolist()):\n",
    "    tmp_score = st.sentence_similarity(t1, t2)\n",
    "    bank_score_st.append(tmp_score)\n",
    "df_bank['st_score'] = bank_score_st\n",
    "\n",
    "# calculate MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "res_bank_st = mean_squared_error(df_bank.score.tolist(), df_bank.st_score.tolist())\n",
    "\n",
    "res_normal_st = mean_squared_error(df_normal.score.tolist(), df_normal.st_score.tolist())\n",
    "\n",
    "print('bank w2v avg embed MSE: ', res_bank_st)\n",
    "\n",
    "print('normal w2v avg embed MSE: ', res_normal_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "01c4f3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normal.to_excel(dir_path+'normal_QC.xlsx', index=False)\n",
    "df_bank.to_excel(dir_path+'bank_QC.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f0ece10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank EditDistance MSE:  0.3121040805733899\n",
      "bank SimHash MSE:  0.25456280156941313\n",
      "bank w2v cos avg MSE:  0.33497529899181905\n",
      "bank st cos avg embed MSE:  0.21352857993357788 \n",
      "\n",
      "normal EditDistance MSE:  0.048148436281209364\n",
      "normal SimHash MSE:  0.24849385616796132\n",
      "normal w2v cos avg embed MSE:  0.43082670450919386\n",
      "normal st cos avg embed MSE:  0.02366014663656099\n"
     ]
    }
   ],
   "source": [
    "# calculate MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "res_bank_ed = mean_squared_error(df_bank.score.tolist(), df_bank.ed_score.tolist())\n",
    "res_bank_sh = mean_squared_error(df_bank.score.tolist(), df_bank.simhash_score.tolist())\n",
    "res_bank_st = mean_squared_error(df_bank.score.tolist(), df_bank.st_score.tolist())\n",
    "res_bank_w2v = mean_squared_error(df_bank.score.tolist(), df_bank.w2v_score.tolist())\n",
    "\n",
    "res_normal_ed = mean_squared_error(df_normal.score.tolist(), df_normal.ed_score.tolist())\n",
    "res_normal_sh = mean_squared_error(df_normal.score.tolist(), df_normal.simhash_score.tolist())\n",
    "res_normal_w2v = mean_squared_error(df_normal.score.tolist(), df_normal.w2v_score.tolist())\n",
    "res_normal_st = mean_squared_error(df_normal.score.tolist(), df_normal.st_score.tolist())\n",
    "\n",
    "print('bank EditDistance MSE: ', res_bank_ed)\n",
    "print('bank SimHash MSE: ', res_bank_sh)\n",
    "print('bank w2v cos avg MSE: ', res_bank_w2v)\n",
    "print('bank st cos avg embed MSE: ', res_bank_st, '\\n')\n",
    "\n",
    "print('normal EditDistance MSE: ', res_normal_ed)\n",
    "print('normal SimHash MSE: ', res_normal_sh)\n",
    "print('normal w2v cos avg embed MSE: ', res_normal_w2v)\n",
    "print('normal st cos avg embed MSE: ', res_normal_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3d2049c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP-EditDistance bank: 0.7675\n",
      "MAP-SimHash bank: 0.7572\n",
      "MAP-w2v Cos bank: 0.7548\n",
      "MAP-MiniLM SentenceBert Cos bank: 0.8265\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "def one2two(labels):\n",
    "    res = []\n",
    "    for i in labels:\n",
    "        res.append([1-i, i])\n",
    "    return res\n",
    "\n",
    "def compute_mAP(labels,outputs):\n",
    "    y_true = np.array(one2two(labels))\n",
    "    y_pred = np.array(one2two(outputs))\n",
    "\n",
    "    AP = []\n",
    "    for i in range(y_true.shape[0]):\n",
    "        AP.append(average_precision_score(y_true[i],y_pred[i]))\n",
    "    return np.mean(AP)\n",
    "\n",
    "b_true = df_bank.score.tolist()\n",
    "n_true = df_normal.score.tolist()\n",
    "\n",
    "b_ed_pred = df_bank.ed_score.tolist()\n",
    "n_ed_pred = df_normal.ed_score.tolist()\n",
    "\n",
    "b_sh_pred = df_bank.simhash_score.tolist()\n",
    "n_sh_pred = df_normal.simhash_score.tolist()\n",
    "\n",
    "b_w2v_pred = df_bank.w2v_score.tolist()\n",
    "n_w2v_pred = df_normal.w2v_score.tolist()\n",
    "\n",
    "b_st_pred = df_bank.st_score.tolist()\n",
    "n_st_pred = df_normal.st_score.tolist()\n",
    "\n",
    "res_b_ed = compute_mAP(b_true, b_ed_pred)\n",
    "res_b_sh = compute_mAP(b_true, b_sh_pred)\n",
    "res_b_w2v = compute_mAP(b_true, b_w2v_pred)\n",
    "res_b_st = compute_mAP(b_true, b_st_pred)\n",
    "\n",
    "print('MAP-EditDistance bank: %.4f' % res_b_ed)\n",
    "print('MAP-SimHash bank: %.4f' % res_b_sh)\n",
    "print('MAP-w2v Cos bank: %.4f' % res_b_w2v)\n",
    "print('MAP-MiniLM SentenceBert Cos bank: %.4f' % res_b_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec370b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
